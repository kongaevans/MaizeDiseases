{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing dependencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import dependencies\nimport os\nimport numpy as np\nimport  pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers import Dropout, Dense, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nimport pathlib\nimport random\nimport warnings\nimport cv2\nfrom tensorflow.keras import backend as K\nimport tensorflow_hub as hub\nfrom sklearn.utils.class_weight import compute_class_weight\nimport seaborn as sns\nwarnings.filterwarnings(\"ignore\")\nsns.set()","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling data preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data directories\ndatadir = \"../input/maizedisease/data/\"","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# process the data paths\ndataroot = pathlib.Path(datadir)\nall_images = dataroot.glob(\"*/*\")\nall_images = [str(path) for path in all_images]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# process the paths to a correct format\nall_image_paths = []\nfor i in all_images:\n    if i == '../input/maizedisease/data/fall army worm/.ipynb_checkpoints':\n        del i\n    else:\n        all_image_paths.append(i)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting the label names\nlabel_names = sorted(item.name for item in dataroot.glob('*/') if item.is_dir())\nlabel_names","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"['fall army worm',\n 'healthy',\n 'herbicide burn',\n 'magnesium deficiency',\n 'maize streak',\n 'multiple',\n 'nitrogen deficiency',\n 'potassium deficiency',\n 'stalk borer',\n 'sulphur deficiency',\n 'zinc deficiency']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert label names to index\nlabel_to_index = dict((name, index) for index,name in enumerate(label_names))\nlabel_to_index","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"{'fall army worm': 0,\n 'healthy': 1,\n 'herbicide burn': 2,\n 'magnesium deficiency': 3,\n 'maize streak': 4,\n 'multiple': 5,\n 'nitrogen deficiency': 6,\n 'potassium deficiency': 7,\n 'stalk borer': 8,\n 'sulphur deficiency': 9,\n 'zinc deficiency': 10}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the all image labels\nall_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n                    for path in all_image_paths]\n\nprint(\"First 10 labels indices: \", all_image_labels[:10])","execution_count":7,"outputs":[{"output_type":"stream","text":"First 10 labels indices:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load images to arrays\nimage_array = []\nfor i in all_image_paths:\n    img = cv2.imread(i)\n    img_array = cv2.resize(img,(224,224),3)\n    image_array.append(img_array)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert the data to array\ntrain_x=np.array(image_array)\ntrain_y=np.array(all_image_labels)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# url for the pretrained model\nfeature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/3\" #@param {type:\"string\"}","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining a feature extractor function\ndef feature_extractor(x):\n    feature_extractor_module = hub.Module(feature_extractor_url)\n    return feature_extractor_module(x)\n\n# get required image size\nIMAGE_SIZE = hub.get_expected_image_size(hub.Module(feature_extractor_url))\nIMAGE_SIZE","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"[224, 224]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Wraping the module in a keras layer\nfeatures_extractor_layer = tf.keras.layers.Lambda(feature_extractor, input_shape=IMAGE_SIZE+[3])","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set the layers to be non trainable\nfeatures_extractor_layer.trainable = False","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Attaching a classification head\nmodel = tf.keras.Sequential([\n  features_extractor_layer,\n  tf.keras.layers.Dense(11, activation='softmax')\n])\nmodel.summary()","execution_count":26,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlambda_1 (Lambda)            (None, 1001)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 11)                11022     \n=================================================================\nTotal params: 11,022\nTrainable params: 11,022\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define sessions\nsess = K.get_session()\ninit = tf.global_variables_initializer()","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize the TFHub module.\ninit = tf.global_variables_initializer()\nsess.run(init)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compiling the model\nmodel.compile(\n  optimizer=tf.keras.optimizers.Adam(), \n  loss='sparse_categorical_crossentropy',\n  metrics=['accuracy'])","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class to collect the training logs\nclass CollectBatchStats(tf.keras.callbacks.Callback):\n    def __init__(self):\n        self.batch_losses = []\n        self.batch_acc = []\n\n    def on_batch_end(self, batch, logs=None):\n        self.batch_losses.append(logs['loss'])\n        self.batch_acc.append(logs['acc'])","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compute the class weight to handle imbalanced class\nclass_weight = compute_class_weight('balanced', np.unique(train_y),\n                                train_y)\nclass_weight","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"array([ 0.13156693,  2.06698565,  2.70846395, 11.22077922,  5.23636364,\n        2.31016043, 19.63636364, 39.27272727, 11.22077922, 26.18181818,\n        0.61363636])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compute steps per epoch and define the batches\nsteps_per_epoch = len(image_array)//32\nbatch_stats = CollectBatchStats()","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model\nmodel.fit(train_x,y = train_y,epochs=15, \n                    steps_per_epoch=steps_per_epoch,\n                    callbacks = [batch_stats],batch_size=32, class_weight=class_weight)","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/15\n10/27 [==========>...................] - ETA: 23s - loss: 2.6485 - acc: 0.4122","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize the training results (loss)\nplt.figure()\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Training Steps\")\nplt.ylim([0,2])\nplt.plot(batch_stats.batch_losses)\nplt.title(\"Model Loss\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize the training results (accuracy)\nplt.figure()\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Training Steps\")\nplt.ylim([0,1])\nplt.plot(batch_stats.batch_acc)\nplt.title(\"Model Accuracy\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict for new image"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = cv2.imread(all_image_paths[520])\ntest = cv2.resize(test,(224,224),3)\nplt.imshow(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_image_paths[520]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.reshape(1,224,224,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(test)\npred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_label = label_names[np.argmax(pred)]\npredicted_label","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}